{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Installs the required packages"
      ],
      "metadata": {
        "id": "LgQTg1P9TEXa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "936zQ9CMS1r8"
      },
      "outputs": [],
      "source": [
        "# Installs packages\n",
        "!pip install --q --upgrade pip flash-attn --no-build-isolation git+https://github.com/huggingface/transformers.git accelerate datasets[audio]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports the required packages"
      ],
      "metadata": {
        "id": "COCQiIv_TZD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline"
      ],
      "metadata": {
        "id": "TmTMVdGLTIm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sets up the device and data types"
      ],
      "metadata": {
        "id": "QzDAS0pDHKoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32"
      ],
      "metadata": {
        "id": "AmCKPszcTmCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specifies the model"
      ],
      "metadata": {
        "id": "rcHvcnM8HOnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Other available model variants can be found here: https://huggingface.co/openai/whisper-large-v3#:~:text=on%20the%20Hub%3A-,Size,%E2%9C%93,-Usage\n",
        "model_id = \"openai/whisper-large-v3\""
      ],
      "metadata": {
        "id": "ooBD5NvjTycZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializes and configures the model and the processor"
      ],
      "metadata": {
        "id": "6A39mY18HVFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=False, use_safetensors=True\n",
        "    # Use Flash Attention if you have a GPU that supports it (Ampere and newer)\n",
        "    # ,use_flash_attention_2=True\n",
        ").to(device)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "_YH8j6fxT1Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configures the pipeline"
      ],
      "metadata": {
        "id": "sTOb-GU2HXwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=model,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    max_new_tokens=420,\n",
        "    chunk_length_s=8, # Adjust this based on the type of audio content\n",
        "    batch_size=8, # Adjust this based on your hardware (Fine for T4 GPU)\n",
        "    return_timestamps=True, # Set this to false if you don't want/need timestamps\n",
        "    torch_dtype=torch_dtype,\n",
        "    device=device,\n",
        ")"
      ],
      "metadata": {
        "id": "o6qK5IkCT7uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specifies the audio file path and filetype"
      ],
      "metadata": {
        "id": "O0w2io7qHamf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Place your audio file into Google Colabs \"/content/\" directory and\n",
        "# change \"your_file\" to your files name\n",
        "audio = \"/content/\" + \"interview_mum\" + \".mp3\""
      ],
      "metadata": {
        "id": "LQw1oo47WhWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sets the language and task (Transcription, Translation)"
      ],
      "metadata": {
        "id": "rLKxtYatHoQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this for transcription (Change <\"language\": \"german\"> to your audio files language)\n",
        "result = pipe(audio, generate_kwargs={\"language\": \"german\", \"task\": \"transcribe\"})\n",
        "\n",
        "# Use this for translation to English (Change <\"language\": \"german\"> to your audio files language)\n",
        "# result = pipe(audio, generate_kwargs={\"language\": \"german\", \"task\": \"translate\"})"
      ],
      "metadata": {
        "id": "fOkgbwPB8vi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formats the output and saves it to a text file"
      ],
      "metadata": {
        "id": "yJjcq9i_HuFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Formats the timestamps to be more readable\n",
        "def format_time(seconds):\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    seconds = int(seconds % 60)\n",
        "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
        "\n",
        "# Saves the Models Output to a text file in Google Colabs \"/content/\" directory\n",
        "with open(\"/content/whisper_output.txt\", \"w\", encoding='utf-8') as file:\n",
        "    for i, chunk in enumerate(result['chunks']):\n",
        "        start_time, end_time = chunk['timestamp']\n",
        "        formatted_start_time = format_time(start_time)\n",
        "        formatted_end_time = format_time(end_time)\n",
        "        text = chunk['text']\n",
        "        file.write(f\"Segment {i+1}:\\n\")\n",
        "        file.write(f\"Start Time: {formatted_start_time}, End Time: {formatted_end_time}\\n\\n\")\n",
        "        file.write(f\"Text: {text}\\n\")"
      ],
      "metadata": {
        "id": "zAT5moxR6FyQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}